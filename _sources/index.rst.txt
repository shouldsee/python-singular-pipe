.. singular_pipe documentation master file, created by
   sphinx-quickstart on Mon Mar  9 23:15:33 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.
.. check https://docs.python.org/2/_sources/

********************************************************************
Welcome to :mod:`singular_pipe`-|version| 's documentation!
********************************************************************

.. _Contents

.. toctree::
   :maxdepth: 2
   :numbered:
   
   install/index.rst
   example_usage.rst
   lib/index.rst
   indexes.rst
   license.rst

Overview
===================

Despite plenty of packages out there, writing reproducible python
scripts is not yet a simple task. :obj:`singular_pipe` is written to address
serveral aspects:
  * Workflow execution as a file synchronisation process.
  * Separation of code from data.
  * Declaring function-level dependency.

Workflow execution as file synchronisation
-------------------------------------------

Any workflow can be divided into two parts: code and data. Given 
a data state, one can apply some code to check whether these data
are outdated. Executing any workflow can be abstracted to a chain of 
sequential changes to local/remote files from upstream to downstream.
If all files are up-to-date as checked by the code, then nothing needs
to be updated. 

To write such codes, file states must be explicitly monitored and remembered.
In :mod:`singular_pipe` this is achieved through a set of custom eval-like function
called :obj:`Runner` and functions with a specialised signature called :obj:`Node`
or :obj:`Flow`. :obj:`Runner` would 
extract file dependency graph from the function signatures and use this information
to make runtime decisions as to whether to skip a function evaluation.::
    from singular_pipe.types import Node, Flow, File

    @Node  # Omittable because Node is the default.
    def some_node( self, #### Essn. A runtime object of type singular_pipe.runner.Caller
      prefix,            #### Essn. A local file where a realised node would live
      input = File,      #### remembered argument,
      _some_const='foo', #### private constants, 
      _output=['txt']    #### Essn. private constants to specify output monitoring
      ):
      print('... running [some_node]')
      with open(input,'r') as f:
        buf = ( f.read() + _some_const )*5 
      with open( self.output.txt, 'w') as f:
        f.write(buf)
      return self
    if __name__ == '__main__':
      from singular_pipe.runner import cache_run, get_changed_files
      from pprint import pprint
      fs = get_all_files(some_node, '/tmp/some_node', '/tmp/input_file.txt')
      print('##### all files governed by this node #######')
      pprnit(fs)

      fs = get_changed_files(some_node, '/tmp/some_node', '/tmp/input_file.txt')
      print('##### files changed in the next execution of this node #######')      
      pprnit(fs) 

      print('#### write some input file ###')
      with open('/tmp/input_file.txt','w') as f: f.write('barbarfoo\n')

      print('#### actual execution #####')
      cache_run(some_node, '/tmp/some_node', '/tmp/input_file.txt')

      print('#### the second execution is skipped ###')
      cache_run(some_node, '/tmp/some_node', '/tmp/input_file.txt')

      #### the fact that the execution is skipped implies
      #### that executing this node would not change any file
      fs = get_changed_files(some_node, '/tmp/some_node', '/tmp/input_file.txt')
      print('##### files changed in the next execution of this node #######')      
      pprnit(fs) 
      assert fs == []

 









:Author: Feng Geng
:Email: shouldsee.gem@gmail.com

